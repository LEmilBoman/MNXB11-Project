
<!--unsure what we are going to keep from the old skeleton so i will create this new section to have something to work with -->

# Adding external software libraries

You can either run our small install script or install the libraries manually. 

Your location should be the root of the project.

To use our script type 
```
./dependency_install.sh
```
else if you want to do it manually follow below instructions.

create the the build, external and dependencies folder (the dependencies name is optional. This is just a folder to clone external libraries into)
```
mkdir build external dependencies
```

### Installing argumentum
Go to dependencies and clone the following (or to go to https://github.com/mmahnic/argumentum to find other adresses if you do not use ssh)
```
git clone git@github.com:mmahnic/argumentum.git
```
Go into the build folder and create a folder for the argumentum build
```
mkdir argumentum
```
Go into this newly created folder and run the following (dependencies in the below code will need to be changed to the name of the folder you chose above if you chose a different name)
```
-cmake ../../dependencies/argumentum/ -DCMAKE_INSTALL_PREFIX=../../external/
```
install it
```
make install
```
### Adding lazycsv as a dependency

Create a folder for external dependencies external/include if it doesnt exist yet. Lazycsv is a header only library consisting of a single header lazycsv.hpp.
Download the header file from https://github.com/ashtum/lazycsv.git and put the header file into the external/include folder.

### Adding Date
Date is a header only library which is part of the https://github.com/HowardHinnant/date project. If you want a copy of the entire project clone it into the folder /dependencies.

The Date library consists of the single header file /date/include/date/date.h. 

If you made a clone of the entire project: Copy this file (using  cp) into the /external/include directory. 

If you did not clone the entire project: Download the header file and place it in the
/external/include directory.



## Cleaning data
Inside the /datasets directory there is a bash script called "cleanData.sh", which generates cleaned versions of datasets. To use it: Run the script giving the name of each file to be cleaned as input.

```
./cleanData.sh *first file* *second file* *etc...*
```

The copy generated by the script has the same name as the original file, but with the addition "_clean" before .csv .

The script extracts the first 3 columns of each data line. The line syntax is: date;time;temperature.

The script changes the ";"-seperation to ","-separation.

## Pre C++ processing for Compare number of winter days per year in Lund, Uppsala, and Luleå.
Inside the /dataset directory there is a bash script called "negTempDays.sh", which extracts all days with any negative temperatures from cleaned datasets, starting from 1964.

To use it: Run the script giving the name of each cleaned dataset file as input. The script generates a new csv dataset for each input with the same name as the input file, but with the addition "_neg" before .csv .

```
./negTempDays.sh *first file_clean.csv* *second file_clean.csv* *etc...*
```

## C++ data processing and plot generation for the subproject "Compare number of winter days per year in Lund, Uppsala, and Luleå".
winterdays is used in order to 

Time period treated: Data between 1964 and 2022 is ploted.

Space-Separated CLI: The names (with paths) for three csv files containing temperature data, and the three names that should be used as labels for the datasets. The csv files needs to be ones obtained using negTempDays.sh (see above).

NOTE: the flag -f is used to indicate input files, while the flag -n is used to indicate name inputs (see example below).
            
NOTE: the datasets should be given in number of winterdays order, beginning with the set with the lowest number of winterdays per year. This is in order for larger histograms not to cover smaller ones.

NOTE: The order of the data files and the order of the corresponding names must be the same.

```
./winterdays -f *path/first file* *path/second file* *path/third file* -n *first_name* *second_name* *third_name*
```


###Data Processing: 

The number of winterdays per year is calculated (the condition for a winterday is that the average temperature should be below zero C).
                            
The simple moving average is calculated using centralized 5 year intervalls. 

The relative number of winterdays per for the first two datasets are also calculated, using the third dataset as the baseline.


###Plot Generation: 

The data is stored in histograms and ploted. The number of winterday histograms with corresponding moving averages are plotted together. 

The relative number of winterdays histograms are ploted alone. 

## Pre c++ data processing for MinMaxtemp 
inside the /dataset directory there is a bash script called "MaxMinPerYear.sh" which takes cleaned csv files as input and output files_MINMAX.csv. create MinMax version of the data you want to use.
## How to use MinMaxTemp
type the following in root
```
make MinMaxTemp
```
then type 
```
./MinMaxTemp -f *yourfile*.csv -n *name of city
```
This program takes on datafile at a time and produces a pdf with the data.

## Data pre-processing for the tempertaure delta sub-project

First the data sets used in the sub-project need to be cleaned by using the cleanData.sh script located in the datasets directory. As an example when used on the Lund and Lulea smhi datasets
```
./cleanData.sh smhi-opendata_1_53430_20231007_155558_Lund.csv smhi-opendata_1_162860_20231007_155220_Lulea.csv
```

This would create a new csv file with the same name and _clean decorator at the end.

Afterwards use the cut_to_size.sh script in order to cut out the relevant time interval from both data files.

```
./cut_to_size.sh smhi-opendata_1_53430_20231007_155558_Lund_clean.csv smhi-opendata_1_162860_20231007_155220_Lulea_clean.csv
```

The script will then ask for the start date and the end date for this set of data 1949-01-01 and 2022-12-31 were used respectivly. This will create the new data sets with a _cut decorator at the end. This data sets then should be processed.

## Running the main executable

After running 
```
make
```
a binary file main is created one can use it in order to read out the example data from csv_example.csv or do data processing for the temperature delta project. In order to run the temperature delta project do
```
./main -d datasets/smhi-opendata_1_53430_20231007_155558_Lund_clean_cut.csv datasets/smhi-opendata_1_162860_20231007_155220_Lulea_clean_cut.csv
```
This will create 4 different plots, an individual plot for each of the data sets an plot of the delta through out the whole time period and a plot for average temperature difference sorted by month.
